{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Практическая работа №1\n",
    "## Предварительная обработка данных\n",
    "Выполнил: Терентьев Никита Александрович КИ21-16/1б\n",
    "Вариант: 21\n",
    "## Цель работы\n",
    "Знакомство с основными задачами предварительной обработки исходных данных, изучение основных методов предварительной обработки данных, формирование навыков выполнения предварительной обработки исходных данных с помощью языка программирования Python.\n",
    "## Задачи\n",
    "Выполнение практической работы предполагает решение следующих задач:\n",
    "1. Визуальный анализ исходных данных\n",
    "2. Поиск аномальных значений\n",
    "3. Поиск и восстановление отсутствующих значений\n",
    "4. Преобразование данных\n",
    "## Ход работы\n",
    "Был произведён импорт необходимых библиотек."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.linalg.linalg' has no attribute '__all__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpute\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\1 lab\\lib\\site-packages\\pandas\\__init__.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _dependency \u001B[38;5;129;01min\u001B[39;00m _hard_dependencies:\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 11\u001B[0m         \u001B[38;5;28;43m__import__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_dependency\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m _e:\n\u001B[0;32m     13\u001B[0m         _missing_dependencies\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_dependency\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_e\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\1 lab\\lib\\site-packages\\numpy\\__init__.py:143\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compat\n\u001B[1;32m--> 143\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m lib\n\u001B[0;32m    144\u001B[0m \u001B[38;5;66;03m# NOTE: to be revisited following future namespace cleanup.\u001B[39;00m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;66;03m# See gh-14454 and gh-15672 for discussion.\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\1 lab\\lib\\site-packages\\numpy\\lib\\__init__.py:25\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# Private submodules\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtype_check\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mindex_tricks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunction_base\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnanfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\1 lab\\lib\\site-packages\\numpy\\lib\\index_tricks.py:12\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumeric\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      8\u001B[0m     asarray, ScalarType, array, alltrue, cumprod, arange, ndim\n\u001B[0;32m      9\u001B[0m )\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumerictypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m find_common_type, issubdtype\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmatrixlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmatrixlib\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunction_base\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m diff\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmultiarray\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ravel_multi_index, unravel_index\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\1 lab\\lib\\site-packages\\numpy\\matrixlib\\__init__.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"Sub-package containing the matrix class and related functions.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdefmatrix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      6\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m defmatrix\u001B[38;5;241m.\u001B[39m__all__\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytesttester\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PytestTester\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\1 lab\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:11\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moverrides\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m set_module\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# While not in __all__, matrix_power used to be defined here, so we import\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# it for backward compatibility.\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinalg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m matrix_power\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_convert_from_string\u001B[39m(data):\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m char \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[]\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\1 lab\\lib\\site-packages\\numpy\\linalg\\__init__.py:76\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m linalg\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinalg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m---> 76\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m \u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__all__\u001B[49m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytesttester\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PytestTester\n\u001B[0;32m     79\u001B[0m test \u001B[38;5;241m=\u001B[39m PytestTester(\u001B[38;5;18m__name__\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy.linalg.linalg' has no attribute '__all__'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.impute\n",
    "\n",
    "from scipy.stats import sigmaclip\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "from draw_functions import build_bar_and_pie_chart, build_histogram_density_diagram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Произведено чтение файла и взятие нужных колонок из таблицы в соответствии с вариантом."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe = pd.read_excel(r\"C:\\Users\\nikit\\Desktop\\Программирование\\4 семестр\\data_analysis_methods\\1 lab\\data\\first_practice_dataframe.xlsx\")\n",
    "# Названия колонок датафрейма храним в константах\n",
    "qualitative_variables = [\"cat1_gender\", \"cat3_education\"]\n",
    "quantitative_variables = [\"num1_22\", \"num2_22\", \"num3_22\"]\n",
    "dataframe = dataframe[[*qualitative_variables, *quantitative_variables]]\n",
    "initial_dataframe = dataframe.copy()\n",
    "dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем типы данных в нашем датафрейме."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Визуальный анализ данных\n",
    "Были построены графики для визуального представления каждого столбца(признака) в исходном наборе данных.\n",
    "Все функции для построения графиков были вынесены в отдельный файл functions.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in qualitative_variables:\n",
    "    build_bar_and_pie_chart(dataframe[column], column)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    try:\n",
    "        build_histogram_density_diagram(dataframe[column],column)\n",
    "    except TypeError:\n",
    "        print(f\"График признака {column} не может быть построен, так как столбец содержит не только числовые значения.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Проверка правдоподобности исходных данных\n",
    "Проанализировав полученные графики, можно сделать вывод, что некоторые значения из таблицы являются некорректными (например, пропуски значений)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Приведение значений качественных признаков\n",
    "Приведём значения качественных признаков к нужному формату (всем пустым значениям был присвоен тип None, признаки, отличающиеся типом написания, были приведены к одному виду). Также первая и вторая колонка были приведены к категориальному типу."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in qualitative_variables:\n",
    "    dataframe[column].replace({\" \": None, \"-\": None, np.nan: None}, inplace=True)\n",
    "    dataframe[column] = dataframe[column].apply(lambda x: x.capitalize() if isinstance(x, str) else x)\n",
    "    dataframe[column] = dataframe[column].astype(\"category\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Приведение значений количественных признаков"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    # Если errors='coerce', то недопустимый синтаксический анализ будет установлен как NaN.\n",
    "    dataframe[column] = pd.to_numeric(dataframe[column], errors='coerce')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем ещё раз все графики."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in qualitative_variables:\n",
    "    build_bar_and_pie_chart(dataframe[column], column)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    try:\n",
    "        build_histogram_density_diagram(dataframe[column],column)\n",
    "    except TypeError:\n",
    "        print(f\"График признака {column} не может быть построен, так как столбец содержит не только числовые значения.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Все данные были приведены к нужному формату. Все качественные признаки имеют тип category, все количественные - float64."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Поиск аномальных значений\n",
    "Было произведено копирование датафрейма."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe_copy = dataframe.copy()\n",
    "dataframe_sigma = dataframe.copy()\n",
    "dataframe_quantile = dataframe.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Метод сигм\n",
    "Выведем изначальное количество значений"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    print(f\"Количество не пустых значений в параметре {column}: {dataframe_sigma[column].count()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigma_method(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Удаляет выбросы из числовых столбцов фрейма данных, используя метод сигма.\n",
    "    :param dataframe: Датафрейм\n",
    "    :return: Датафрейм после удаления выбросов.\n",
    "    \"\"\"\n",
    "    numerical_columns = dataframe.select_dtypes(include=['float']).columns\n",
    "    for column in numerical_columns:\n",
    "        data = dataframe[column].dropna()\n",
    "        clean_data, low, high = sigmaclip(data, low=3, high=3)\n",
    "        dataframe = dataframe.loc[dataframe.loc[:, column].isin(clean_data) | dataframe.loc[:, column].isna()]\n",
    "    return dataframe.loc[dataframe.loc[:, numerical_columns[0]].notna()]\n",
    "\n",
    "dataframe_sigma = sigma_method(dataframe_sigma)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем количество значений после удаления выбросов c помощью метода сигм."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    print(f\"Количество не пустых значений в параметре {column}: {dataframe_sigma[column].count()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    try:\n",
    "        build_histogram_density_diagram(dataframe_sigma[column],column)\n",
    "    except TypeError:\n",
    "        print(f\"График признака {column} не может быть построен, так как столбец содержит не только числовые значения.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Метод квантилей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def quantile_method(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Метод квантилей\n",
    "    :param dataframe: Датафрейм\n",
    "    :return: измененный Датафрейм с удалёнными выбросами\n",
    "    \"\"\"\n",
    "    num_colums = dataframe.select_dtypes(include=['float']).columns\n",
    "    q25 = dataframe[num_colums].quantile(0.25)\n",
    "    q75 = dataframe[num_colums].quantile(0.75)\n",
    "    delta = q75 - q25\n",
    "    low = q25 - 1.5 * delta\n",
    "    high = q75 + 1.5 * delta\n",
    "    filtered_dataframe = dataframe[\n",
    "        ~((dataframe[num_colums] < low) | (dataframe[num_colums] > high)).any(axis=1)]\n",
    "    filtered_dataframe = filtered_dataframe.reset_index(drop=True)\n",
    "    return filtered_dataframe\n",
    "\n",
    "dataframe_quantile = quantile_method(dataframe_quantile)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    print(f\"Количество не пустых значений в параметре {column}: {dataframe_quantile[column].count()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    try:\n",
    "        build_histogram_density_diagram(dataframe_quantile[column],column)\n",
    "    except TypeError:\n",
    "        print(f\"График признака {column} не может быть построен, так как столбец содержит не только числовые значения.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Используем результаты очистки данных, полученных с помощью метода сигм."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe = dataframe_sigma"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Поиск и восстановление пропущенных значений\n",
    "Узнаем количество пропущенных значений в нашем датафрейме."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Всего в датафрейме 893 строки, в 3 столбце столько же значений, следовательно, в нём не надо восстанавливать пропущенные значения. Пропуски значений первого столбца будут заменены значениями, полученными с помощью метода “k-ближайших соседей”."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "first_column = qualitative_variables[0]\n",
    "\n",
    "dataframe_filled = dataframe.copy()\n",
    "\n",
    "nan_index = dataframe_filled[first_column][dataframe_filled[first_column].isna()].index[0]\n",
    "imputer = sklearn.impute.KNNImputer(n_neighbors=5)\n",
    "encoder = LabelEncoder()\n",
    "dataframe_filled[first_column] = encoder.fit_transform(dataframe_filled[first_column])\n",
    "dataframe_filled[first_column] = dataframe_filled[first_column].replace({dataframe_filled[first_column][nan_index]: np.nan})\n",
    "dataframe_filled[first_column] = imputer.fit_transform(dataframe_filled[[first_column]])\n",
    "dataframe_filled[first_column] = dataframe_filled[first_column].apply(lambda x: round(x))\n",
    "dataframe_filled[first_column] = encoder.inverse_transform(dataframe_filled[first_column])\n",
    "dataframe = dataframe_filled\n",
    "print(f'Есть ли nan элементы: {dataframe[first_column].isna().any()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пропуски значений второго признака были заменены самым популярным значением."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "second_column = qualitative_variables[1]\n",
    "most_frequence = dataframe[second_column].value_counts().keys()[0]\n",
    "dataframe[second_column] = dataframe[second_column].fillna(most_frequence)\n",
    "print(f'Есть ли в столбце nan элементы: {dataframe[second_column].isna().any()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пропуски значений четвёртого признака были заменены медианой."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "four_column = quantitative_variables[1]\n",
    "median = dataframe[four_column].median()\n",
    "dataframe[four_column] = dataframe[four_column].fillna(median)\n",
    "print(f'Есть ли в столбце nan элементы: {dataframe[four_column].isna().any()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пропуски значений пятого признака были заменены значениями, полученными методом \"k-ближайших соседей\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fifth_column = quantitative_variables[2]\n",
    "knn_imputer = sklearn.impute.KNNImputer(n_neighbors=3)\n",
    "# Заполняем пропущенные значения в выбранном столбце\n",
    "dataframe[[fifth_column]] = knn_imputer.fit_transform(dataframe[[fifth_column]])\n",
    "print(f'Есть ли в столбце nan элементы: {dataframe[fifth_column].isna().any()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Все значения были восстановлены."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Преобразование данных\n",
    "#### Кодировка категориальных признаков\n",
    "Было выполнена кодировка первого категориального признака с помощью one-hot encoding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(min_frequency=6, sparse_output=False, categories=\"auto\")\n",
    "dataframe_encoded = pd.DataFrame(onehot_encoder.fit_transform(dataframe[[qualitative_variables[0]]]), columns=onehot_encoder.get_feature_names_out())\n",
    "dataframe = dataframe.join(dataframe_encoded)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для второго категориального признака была произведена кодировка при помощи label encoding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe[qualitative_variables[1] + \"lb\"] = LabelEncoder().fit_transform(dataframe[qualitative_variables[1]])\n",
    "dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Преобразование количественных признаков\n",
    "В нормализованном наборе данных значения находятся между 0 и 1. Стандартизированный набор данных имеет нулевое среднее значение и единичную дисперсию (стандартное отклонение). Первый и второй количественный признак были приведены к нормализованному виду."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "dataframe_scaled = pd.DataFrame(min_max_scaler.fit_transform(dataframe[quantitative_variables]), columns=quantitative_variables)\n",
    "dataframe = pd.merge(dataframe, dataframe_scaled, left_index=True, right_index=True, suffixes=('', '_norm'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Третий количественный признак был приведён к стандартизированному виду."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "standart_scaler = StandardScaler()\n",
    "dataframe_scaled = pd.DataFrame(standart_scaler.fit_transform(dataframe[quantitative_variables]), columns=quantitative_variables)\n",
    "dataframe = pd.merge(dataframe, dataframe_scaled, left_index=True, right_index=True, suffixes=('', '_stand'))\n",
    "dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Выводы\n",
    "В ходе работы были изучены основные задачи предварительной обработки исходных данных и методы предварительной обработки данных. Был произведён визуальный анализ исходных данных, поиск аномальных значений, восстановление отсутствующих значений и преобразование данных. Ниже произведено сравнение графиков, построенных по исходным данным и по полученным в результате работы обработанным данным."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем итоговые графики"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in qualitative_variables:\n",
    "    build_bar_and_pie_chart(dataframe[column], column)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in quantitative_variables:\n",
    "    build_histogram_density_diagram(dataframe[column],column)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
